{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b894596dee841d5ab949ce4b5f1f2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1da8bb46f7914e52b9f21f9c644783e2",
              "IPY_MODEL_c9fe946db38346d680ca2f9d396ac5b8",
              "IPY_MODEL_c22eddc766e3468f81c32ec66bd4d2f7"
            ],
            "layout": "IPY_MODEL_36100a3a672e4d60976d210f8ee1e36b"
          }
        },
        "1da8bb46f7914e52b9f21f9c644783e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8323a8bf3d94fd99540b0fe9f547caa",
            "placeholder": "​",
            "style": "IPY_MODEL_2c85d05eb53a497eabe842d75fff6a87",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c9fe946db38346d680ca2f9d396ac5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12023a4af654f5db2909e95c3a3bd31",
            "max": 267844284,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_736debbc67ba43f895eef127daeea28c",
            "value": 267844284
          }
        },
        "c22eddc766e3468f81c32ec66bd4d2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60e5a4af45e4bf48c880c233a0748ea",
            "placeholder": "​",
            "style": "IPY_MODEL_1f0a7cdfc1da4e36bd2037670dbc1a95",
            "value": " 268M/268M [00:03&lt;00:00, 110MB/s]"
          }
        },
        "36100a3a672e4d60976d210f8ee1e36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8323a8bf3d94fd99540b0fe9f547caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c85d05eb53a497eabe842d75fff6a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12023a4af654f5db2909e95c3a3bd31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "736debbc67ba43f895eef127daeea28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d60e5a4af45e4bf48c880c233a0748ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f0a7cdfc1da4e36bd2037670dbc1a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "9b894596dee841d5ab949ce4b5f1f2bd",
            "1da8bb46f7914e52b9f21f9c644783e2",
            "c9fe946db38346d680ca2f9d396ac5b8",
            "c22eddc766e3468f81c32ec66bd4d2f7",
            "36100a3a672e4d60976d210f8ee1e36b",
            "c8323a8bf3d94fd99540b0fe9f547caa",
            "2c85d05eb53a497eabe842d75fff6a87",
            "a12023a4af654f5db2909e95c3a3bd31",
            "736debbc67ba43f895eef127daeea28c",
            "d60e5a4af45e4bf48c880c233a0748ea",
            "1f0a7cdfc1da4e36bd2037670dbc1a95"
          ]
        },
        "id": "vBtoOYr-Ymov",
        "outputId": "6767c1cb-c115-40f4-a9c2-0b62ac3459db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 9482 items\n",
            "Building TF-IDF vectors …\n",
            "Encoding Sentence-BERT embeddings (all-MiniLM-L6-v2) …\n",
            "Computing TF-IDF and BERT similarities to profile …\n",
            "Scoring sentiment with DistilBERT … (this may download a model)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b894596dee841d5ab949ce4b5f1f2bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying filters: Rating>6 & Positive Sentiment …\n",
            "Auto-tuning hyperparameters …\n",
            "Auto-tune finished. Best params: {'alpha': 0.8, 'w_tfidf': 0.4, 'gamma': 0.0, 'lambda_xq': 0.4, 'tau': 0.25}\n",
            "\n",
            "=== Recommendation Metrics (Final) ===\n",
            "Precision@20: 0.7000\n",
            "Recall@20: 0.2800\n",
            "NDCG@20: 0.7852\n",
            "Intra-list Diversity (ILD): 0.9835\n",
            "Novelty (avg −log2 p): 13.1379\n",
            "Coverage: 0.0021\n",
            "Serendipity: 0.4568\n",
            "Sentiment mean: 0.9591, variance: 0.007542\n",
            "Best params -> {'alpha': 0.8, 'w_tfidf': 0.4, 'gamma': 0.0, 'lambda_xq': 0.4, 'tau': 0.25}\n",
            "\n",
            "Saved recommendations -> topN_cleaned_imdb_recs.csv\n",
            "Saved metrics summary -> metrics_cleaned_imdb_summary.csv\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "UAUM + xQuAD Long-Tail Re-ranking + Popularity Penalty\n",
        "Full pipeline script: embeddings, sentiment, UAUM, popularity-penalty, xQuAD re-ranking, auto-tune, metrics, save outputs.\n",
        "\n",
        "Expects: cleaned_dataset.csv with columns: Title, Genre, Description, Director, Cast, Rating, Votes\n",
        "Outputs: topN_cleaned_imdb_recs.csv, metrics_cleaned_imdb_summary.csv\n",
        "\"\"\"\n",
        "\n",
        "# Optional installs if using Colab / fresh env:\n",
        "# !pip install -U sentence-transformers transformers==4.43.3 scikit-learn==1.4.2 pandas numpy tensorflow\n",
        "\n",
        "import os, re, math, random, sys\n",
        "from typing import List, Set, Dict, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "# Sentence-BERT embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Sentiment DistilBERT SST-2 (TF)\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# ----------------------------\n",
        "# Parameters (edit as needed)\n",
        "# ----------------------------\n",
        "CSV_PATH = \"cleaned_dataset.csv\"\n",
        "SEED_TITLES = [\"The Dark Knight\", \"Inception\", \"Interstellar\"]\n",
        "TOP_K = 20\n",
        "\n",
        "# Tail control & candidate pool\n",
        "TAIL_PERCENTILE = 0.2     # bottom 20% votes => Tail\n",
        "TAIL_RATIO = 0.35         # desired minimum fraction of Tail in final Top-K\n",
        "POOL_M = 600              # candidate pool size\n",
        "EXPLORATION_TAIL = 50     # random tail injections\n",
        "SEED = 42\n",
        "\n",
        "# Sentiment\n",
        "SENT_MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "SENT_BATCH = 64\n",
        "SENT_POS_THRESHOLD = 0.0\n",
        "\n",
        "# Auto-tuning grids (tiny by default)\n",
        "DO_AUTOTUNE = True\n",
        "GRID_ALPHAS = [0.6, 0.7, 0.8]         # UAUM alpha (quality vs unexpectedness)\n",
        "GRID_W_TFIDF = [0.4, 0.6, 0.8]        # weight TF-IDF vs BERT for similarity\n",
        "GRID_LAMBDA_XQ = [0.4, 0.5, 0.6]      # xQuAD lambda (diversity mixing)\n",
        "GRID_GAMMA = [0.0, 0.3, 0.6]          # popularity penalty multiplier\n",
        "GRID_TAU = [0.25, 0.35]               # tail ratio (hard enforce) - can match TAIL_RATIO\n",
        "\n",
        "# MISC\n",
        "RANDOM_STATE = SEED\n",
        "np.random.seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "# Output files\n",
        "FINAL_PATH = \"topN_cleaned_imdb_recs.csv\"\n",
        "METRICS_PATH = \"metrics_cleaned_imdb_summary.csv\"\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "def to_int_votes(x):\n",
        "    if pd.isna(x):\n",
        "        return 0\n",
        "    if isinstance(x, str):\n",
        "        x = re.sub(r\"[^0-9]\", \"\", x)\n",
        "        if not x:\n",
        "            return 0\n",
        "        return int(x)\n",
        "    try:\n",
        "        return int(x)\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def softmax_rowwise(logits: np.ndarray):\n",
        "    e = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
        "    return e / e.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Metrics\n",
        "def precision_at_k(recommended: List[int], relevant: Set[int], k: int) -> float:\n",
        "    if k == 0: return 0.0\n",
        "    rec_k = recommended[:k]\n",
        "    return sum(1 for r in rec_k if r in relevant) / k\n",
        "\n",
        "def recall_at_k(recommended: List[int], relevant: Set[int], k: int) -> float:\n",
        "    if not relevant: return 0.0\n",
        "    rec_k = recommended[:k]\n",
        "    return sum(1 for r in rec_k if r in relevant) / len(relevant)\n",
        "\n",
        "def dcg_at_k(recommended: List[int], relevant: Set[int], k: int) -> float:\n",
        "    dcg = 0.0\n",
        "    for i, r in enumerate(recommended[:k], start=1):\n",
        "        rel = 1.0 if r in relevant else 0.0\n",
        "        dcg += (2**rel - 1) / math.log2(i + 1)\n",
        "    return dcg\n",
        "\n",
        "def ndcg_at_k(recommended: List[int], relevant: Set[int], k: int) -> float:\n",
        "    ideal = min(len(relevant), k)\n",
        "    if ideal == 0: return 0.0\n",
        "    idcg = sum((2**1 - 1) / math.log2(i + 1) for i in range(1, ideal + 1))\n",
        "    return dcg_at_k(recommended, relevant, k) / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def intra_list_diversity(recommended: List[int], X_dense_or_sparse) -> float:\n",
        "    if len(recommended) <= 1: return 0.0\n",
        "    sims = cosine_similarity(X_dense_or_sparse[recommended])\n",
        "    n = len(recommended)\n",
        "    iu = np.triu_indices(n, 1)\n",
        "    mean_sim = float(np.mean(sims[iu])) if len(iu[0]) else 0.0\n",
        "    return 1.0 - mean_sim\n",
        "\n",
        "def novelty_bits(recommended: List[int], popularity: np.ndarray) -> float:\n",
        "    pop = popularity.astype(float)\n",
        "    total = pop.sum() if pop.sum() > 0 else 1.0\n",
        "    p = (pop / total)[recommended]\n",
        "    p = np.clip(p, 1e-12, 1.0)\n",
        "    return float(np.mean(-np.log2(p)))\n",
        "\n",
        "def coverage_rate(recommended: List[int], catalog_size: int) -> float:\n",
        "    return len(set(recommended)) / catalog_size\n",
        "\n",
        "def serendipity(recommended: List[int], relevant: Set[int], dissim: np.ndarray) -> float:\n",
        "    vals = [(1.0 if r in relevant else 0.0) * float(dissim[r]) for r in recommended]\n",
        "    return float(np.mean(vals)) if vals else 0.0\n",
        "\n",
        "# ----------------------------\n",
        "# Load data\n",
        "# ----------------------------\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    raise FileNotFoundError(f\"{CSV_PATH} not found. Place cleaned_dataset.csv next to this script.\")\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "required = [\"Title\", \"Genre\", \"Description\", \"Rating\", \"Votes\"]\n",
        "missing = [c for c in required if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "for c in [\"Director\", \"Cast\"]:\n",
        "    if c not in df.columns: df[c] = \"\"\n",
        "\n",
        "df[\"Votes_clean\"] = df[\"Votes\"].apply(to_int_votes)\n",
        "df[\"text\"] = (\n",
        "    df[\"Title\"].astype(str) + \" \\n\" +\n",
        "    df[\"Genre\"].astype(str) + \" \\n\" +\n",
        "    df[\"Director\"].astype(str) + \" \\n\" +\n",
        "    df[\"Cast\"].astype(str) + \" \\n\" +\n",
        "    df[\"Description\"].astype(str)\n",
        ")\n",
        "\n",
        "N = len(df)\n",
        "print(f\"Loaded {N} items\")\n",
        "\n",
        "# ----------------------------\n",
        "# Embeddings: TF-IDF + SBERT\n",
        "# ----------------------------\n",
        "print(\"Building TF-IDF vectors …\")\n",
        "vectorizer = TfidfVectorizer(lowercase=True, strip_accents='unicode', ngram_range=(1,2), max_features=120_000)\n",
        "X_tfidf = vectorizer.fit_transform(df[\"text\"].fillna(\"\"))\n",
        "\n",
        "print(\"Encoding Sentence-BERT embeddings (all-MiniLM-L6-v2) …\")\n",
        "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "X_bert = bert_model.encode(df[\"text\"].tolist(), batch_size=128, convert_to_numpy=True, normalize_embeddings=True)\n",
        "X_bert = np.asarray(X_bert)\n",
        "\n",
        "# ----------------------------\n",
        "# User profile from SEED_TITLES\n",
        "# ----------------------------\n",
        "seed_idx = []\n",
        "for t in SEED_TITLES:\n",
        "    mask = df[\"Title\"].str.contains(re.escape(t), case=False, na=False)\n",
        "    seed_idx.extend(df.index[mask].tolist())\n",
        "seed_idx = sorted(set(seed_idx))\n",
        "if not seed_idx:\n",
        "    raise ValueError(\"None of SEED_TITLES matched titles in the dataset. Please edit SEED_TITLES.\")\n",
        "\n",
        "# profile embeddings\n",
        "profile_tfidf = X_tfidf[seed_idx].mean(axis=0)\n",
        "profile_tfidf = np.asarray(profile_tfidf).reshape(1, -1)\n",
        "profile_bert = X_bert[seed_idx].mean(axis=0)\n",
        "profile_bert = profile_bert / (np.linalg.norm(profile_bert) + 1e-12)\n",
        "profile_bert = profile_bert.reshape(1, -1)\n",
        "\n",
        "# ----------------------------\n",
        "# Similarities: TF-IDF & BERT\n",
        "# ----------------------------\n",
        "print(\"Computing TF-IDF and BERT similarities to profile …\")\n",
        "sim_tfidf = cosine_similarity(X_tfidf, profile_tfidf).ravel()\n",
        "sim_bert = cosine_similarity(X_bert, profile_bert).ravel()\n",
        "\n",
        "# ----------------------------\n",
        "# Sentiment scoring (DistilBERT SST-2)\n",
        "# ----------------------------\n",
        "print(\"Scoring sentiment with DistilBERT … (this may download a model)\")\n",
        "tok = AutoTokenizer.from_pretrained(SENT_MODEL)\n",
        "sent_mdl = TFAutoModelForSequenceClassification.from_pretrained(SENT_MODEL, from_pt=True)\n",
        "\n",
        "texts = df[\"Description\"].astype(str).tolist()\n",
        "sent_scores = []\n",
        "for i in range(0, len(texts), SENT_BATCH):\n",
        "    batch = texts[i:i+SENT_BATCH]\n",
        "    enc = tok(batch, truncation=True, padding=True, max_length=160, return_tensors='tf')\n",
        "    logits = sent_mdl(enc).logits.numpy()\n",
        "    probs = softmax_rowwise(logits)\n",
        "    pos = probs[:,1]; neg = probs[:,0]\n",
        "    sent_scores.extend((pos - neg).tolist())\n",
        "sent_scores = np.array(sent_scores)\n",
        "\n",
        "# ----------------------------\n",
        "# Popularity & aspects\n",
        "# ----------------------------\n",
        "votes = df[\"Votes_clean\"].astype(int).values\n",
        "pop_norm = votes / (votes.max() if votes.max() > 0 else 1)\n",
        "# define Head/Mid/Tail by quantiles (Tail = <= q20, Head >= q80)\n",
        "q_low = np.quantile(votes, TAIL_PERCENTILE)\n",
        "q_high = np.quantile(votes, 1.0 - TAIL_PERCENTILE)\n",
        "def aspect_label(v):\n",
        "    if v <= q_low:\n",
        "        return \"Tail\"\n",
        "    elif v >= q_high:\n",
        "        return \"Head\"\n",
        "    else:\n",
        "        return \"Mid\"\n",
        "aspect = np.array([aspect_label(v) for v in votes])\n",
        "\n",
        "# dissimilarity (hybrid)\n",
        "dissimilarity = 1.0 - 0.5 * (sim_tfidf + sim_bert)\n",
        "\n",
        "# ----------------------------\n",
        "# UAUM / Base score (using initial W_TFIDF etc. but these will vary during auto-tune)\n",
        "# We'll implement functions so we can recompute for different params in grid search.\n",
        "# ----------------------------\n",
        "def compute_hybrid_similarity(sim_tfidf_arr, sim_bert_arr, w_tfidf: float):\n",
        "    \"\"\"weighted linear combination (not min-maxed here)\"\"\"\n",
        "    return w_tfidf * sim_tfidf_arr + (1.0 - w_tfidf) * sim_bert_arr\n",
        "\n",
        "def pred_rating_proxy_from_sim(sim_h):\n",
        "    return 5.0 * (sim_h - sim_h.min()) / (sim_h.max() - sim_h.min() + 1e-8)\n",
        "\n",
        "def popularity_penalty_function(pop_norm_arr, votes_arr, method=\"log\"):\n",
        "    \"\"\"\n",
        "    returns an array penalty in [0, +inf). We'll use f(pop) to be added * gamma.\n",
        "    method: \"linear\" uses pop_norm, \"log\" uses log(1+votes), then minmax scale\n",
        "    \"\"\"\n",
        "    if method == \"linear\":\n",
        "        return pop_norm_arr.copy()\n",
        "    elif method == \"log\":\n",
        "        raw = np.log1p(votes_arr.astype(float))\n",
        "        # min-max scale to [0,1]\n",
        "        return (raw - raw.min()) / (raw.max() - raw.min() + 1e-12)\n",
        "    else:\n",
        "        return pop_norm_arr.copy()\n",
        "\n",
        "def compute_uaum_and_base(alpha: float, w_tfidf: float, gamma: float, pop_pen_method=\"log\"):\n",
        "    \"\"\"\n",
        "    Returns arrays:\n",
        "      - uaum: UAUM(i)\n",
        "      - base: UAUM(i) - gamma * pop_penalty(i)\n",
        "      - pred_proxy, quality, unexpectedness\n",
        "    \"\"\"\n",
        "    sim_h = compute_hybrid_similarity(sim_tfidf, sim_bert, w_tfidf)\n",
        "    pred_proxy = pred_rating_proxy_from_sim(sim_h)\n",
        "    quality = pred_proxy * (1.0 + sent_scores)    # quality with sentiment uplift\n",
        "    unexpectedness = dissimilarity * (1.0 - pop_norm)\n",
        "    uaum = alpha * quality + (1.0 - alpha) * unexpectedness\n",
        "    pop_pen = popularity_penalty_function(pop_norm, votes, method=pop_pen_method)\n",
        "    base = uaum - gamma * pop_pen\n",
        "    return uaum, base, pred_proxy, quality, unexpectedness, pop_pen\n",
        "\n",
        "# ----------------------------\n",
        "# Filtering & Candidate generation\n",
        "# ----------------------------\n",
        "print(\"Applying filters: Rating>6 & Positive Sentiment …\")\n",
        "rating_vals = pd.to_numeric(df[\"Rating\"], errors='coerce').fillna(0).values\n",
        "mask_rating = rating_vals > 6.0\n",
        "mask_sent = sent_scores > SENT_POS_THRESHOLD\n",
        "mask_base = mask_rating & mask_sent\n",
        "\n",
        "# Remove seed items from candidates\n",
        "mask_seed = np.ones(len(df), dtype=bool)\n",
        "mask_seed[seed_idx] = False\n",
        "\n",
        "# we'll use this helper to produce pool and re-rank later given params\n",
        "def build_candidate_pool(base_scores: np.ndarray, candidates_mask: np.ndarray, pool_m=POOL_M, exploration_tail=EXPLORATION_TAIL):\n",
        "    candidates = np.where(candidates_mask & mask_seed)[0].tolist()\n",
        "\n",
        "    # inject random tail items for exploration\n",
        "    tail_indices = np.where(aspect == \"Tail\")[0]\n",
        "    explore = []\n",
        "    if len(tail_indices) > 0 and exploration_tail > 0:\n",
        "        nsel = min(exploration_tail, len(tail_indices))\n",
        "        explore = np.random.choice(tail_indices, size=nsel, replace=False).tolist()\n",
        "\n",
        "    cand_union = sorted(set(candidates + explore))\n",
        "    order = np.argsort(-base_scores[cand_union])\n",
        "    topM = [cand_union[i] for i in order[:min(pool_m, len(order))]]\n",
        "    return topM\n",
        "\n",
        "# ----------------------------\n",
        "# xQuAD re-ranking (aspects = Head/Mid/Tail)\n",
        "# ----------------------------\n",
        "def xquad_rerank(pool_items: List[int], base_scores: np.ndarray, k: int, lambda_xq: float,\n",
        "                 aspect_arr: np.ndarray, P_aspect_user: Dict[str, float] = None):\n",
        "    \"\"\"\n",
        "    Greedy xQuAD re-ranking for aspects {Head, Mid, Tail}.\n",
        "    - pool_items: candidate item indices (ordered or unordered)\n",
        "    - base_scores: array indexed by item -> relevance score\n",
        "    - k: desired final length\n",
        "    - lambda_xq: mixing parameter between relevance and aspect-coverage\n",
        "    - aspect_arr: array mapping each item index to aspect label (\"Head\",\"Mid\",\"Tail\")\n",
        "    - P_aspect_user: dict of aspect priors; if None, uniform but can upweight Tail\n",
        "    \"\"\"\n",
        "    if P_aspect_user is None:\n",
        "        P_aspect_user = {\"Head\": 0.33, \"Mid\": 0.33, \"Tail\": 0.34}\n",
        "\n",
        "    S = []\n",
        "    coverage = {a: 0.0 for a in P_aspect_user.keys()}  # fraction coverage\n",
        "    pool_set = set(pool_items)\n",
        "    # Precompute P(i|a) as deterministic one-hot\n",
        "    def P_i_given_a(item, a):\n",
        "        return 1.0 if aspect_arr[item] == a else 0.0\n",
        "\n",
        "    while len(S) < k and pool_set:\n",
        "        best_item, best_score = None, -1e18\n",
        "        for i in pool_set:\n",
        "            rel = base_scores[i]\n",
        "            # expected coverage gain = sum_a P(a|user) * (1 - coverage_a) * P(i|a)\n",
        "            coverage_boost = 0.0\n",
        "            for a in P_aspect_user:\n",
        "                coverage_boost += P_aspect_user[a] * (1.0 - coverage[a]) * P_i_given_a(i, a)\n",
        "            score = (1.0 - lambda_xq) * rel + lambda_xq * coverage_boost\n",
        "            if score > best_score:\n",
        "                best_item, best_score = i, score\n",
        "        if best_item is None:\n",
        "            break\n",
        "        S.append(best_item)\n",
        "        pool_set.remove(best_item)\n",
        "        # update coverage: simple fraction of selected items per aspect\n",
        "        cnt = len(S)\n",
        "        counts = {a: sum(1 for it in S if aspect_arr[it] == a) for a in coverage}\n",
        "        for a in coverage:\n",
        "            coverage[a] = counts[a] / cnt if cnt > 0 else 0.0\n",
        "    return S\n",
        "\n",
        "# ----------------------------\n",
        "# Hard tail ratio enforcement\n",
        "# ----------------------------\n",
        "def enforce_tail_ratio(selected_list: List[int], base_scores: np.ndarray,\n",
        "                       pool_items: List[int], min_tail_frac: float):\n",
        "    \"\"\"\n",
        "    Ensure at least ceil(min_tail_frac * K) tail items in selected_list by replacing low-base head items.\n",
        "    \"\"\"\n",
        "    K = len(selected_list)\n",
        "    min_tail = int(math.ceil(min_tail_frac * K))\n",
        "    cur_tail = [i for i in selected_list if aspect[i] == \"Tail\"]\n",
        "    if len(cur_tail) >= min_tail:\n",
        "        return selected_list  # ok\n",
        "\n",
        "    deficit = min_tail - len(cur_tail)\n",
        "    # pool_tail: tail items in pool not already selected, sorted by base desc\n",
        "    pool_tail = [i for i in pool_items if aspect[i] == \"Tail\" and i not in selected_list]\n",
        "    pool_tail_sorted = sorted(pool_tail, key=lambda idx: -base_scores[idx])\n",
        "    if not pool_tail_sorted:\n",
        "        return selected_list  # nothing to do\n",
        "\n",
        "    # head_positions: positions of head items in selected_list sorted by ascending base (replace worst)\n",
        "    head_positions = [(pos, it) for pos, it in enumerate(selected_list) if aspect[it] == \"Head\"]\n",
        "    head_positions_sorted = sorted(head_positions, key=lambda tpl: base_scores[tpl[1]])  # smallest base first\n",
        "    replacements = min(deficit, len(pool_tail_sorted), len(head_positions_sorted))\n",
        "    if replacements <= 0:\n",
        "        return selected_list\n",
        "    for r in range(replacements):\n",
        "        pos_to_replace = head_positions_sorted[r][0]\n",
        "        new_item = pool_tail_sorted[r]\n",
        "        selected_list[pos_to_replace] = new_item\n",
        "    return selected_list\n",
        "\n",
        "# ----------------------------\n",
        "# Recommender pipeline wrapper (given hyperparams)\n",
        "# ----------------------------\n",
        "def recommend_with_params(alpha: float, w_tfidf: float, gamma: float,\n",
        "                          lambda_xq: float, tau: float,\n",
        "                          pool_m: int = POOL_M, exploration_tail: int = EXPLORATION_TAIL,\n",
        "                          pop_pen_method=\"log\"):\n",
        "    \"\"\"\n",
        "    Returns: recommended_list (length TOP_K)\n",
        "    \"\"\"\n",
        "    uaum, base, pred_proxy, quality, unexpectedness, pop_pen = compute_uaum_and_base(alpha, w_tfidf, gamma, pop_pen_method)\n",
        "    # candidate mask: rating>6 & positive sentiment\n",
        "    candidates_mask = mask_base.copy()\n",
        "    # remove seeds already by mask_seed when building pool\n",
        "    pool = build_candidate_pool(base, candidates_mask, pool_m, exploration_tail)\n",
        "    if len(pool) == 0:\n",
        "        return []\n",
        "\n",
        "    # xQuAD re-rank\n",
        "    # set P(aspect|user): we can upweight Tail slightly to encourage its selection\n",
        "    P_aspect_user = {\"Head\": 0.25, \"Mid\": 0.40, \"Tail\": 0.35}\n",
        "    selected = xquad_rerank(pool, base, TOP_K, lambda_xq=lambda_xq, aspect_arr=aspect, P_aspect_user=P_aspect_user)\n",
        "\n",
        "    # enforce tail ratio hard constraint\n",
        "    selected_final = enforce_tail_ratio(selected, base, pool, min_tail_frac=tau)\n",
        "    # If selected_final has fewer than TOP_K (because pool small), pad with highest base from pool not selected\n",
        "    if len(selected_final) < TOP_K:\n",
        "        remaining = [i for i in pool if i not in selected_final]\n",
        "        remaining_sorted = sorted(remaining, key=lambda idx: -base[idx])\n",
        "        to_add = remaining_sorted[:(TOP_K - len(selected_final))]\n",
        "        selected_final.extend(to_add)\n",
        "    return selected_final\n",
        "\n",
        "# ----------------------------\n",
        "# Surrogate ground truth (for tuning): top-50 by hybrid sim_h & rating>6\n",
        "# We'll define relevant indices to compute recall/precision for autotune objective\n",
        "# ----------------------------\n",
        "# Use current default weights for initial ground truth sim_h (w=0.5)\n",
        "sim_h_initial = compute_hybrid_similarity(sim_tfidf, sim_bert, 0.5)\n",
        "sim_hybrid = sim_h_initial  # save\n",
        "rel_mask = mask_rating  # rating>6 as relevant flag\n",
        "# choose top-50 by hybrid sim (and rating>6)\n",
        "sorted_by_sim = np.argsort(-sim_hybrid)\n",
        "top50 = [i for i in sorted_by_sim if rel_mask[i]][:50]\n",
        "relevant_indices = set(top50)\n",
        "\n",
        "# ----------------------------\n",
        "# Auto-tuning (grid search)\n",
        "# ----------------------------\n",
        "best_params = {\"alpha\": 0.7, \"w_tfidf\": 0.6, \"gamma\": 0.0, \"lambda_xq\": 0.5, \"tau\": TAIL_RATIO}\n",
        "best_obj = -1e18\n",
        "best_list = []\n",
        "if DO_AUTOTUNE:\n",
        "    print(\"Auto-tuning hyperparameters …\")\n",
        "    for a in GRID_ALPHAS:\n",
        "        for w in GRID_W_TFIDF:\n",
        "            for lam in GRID_LAMBDA_XQ:\n",
        "                for g in GRID_GAMMA:\n",
        "                    for tau in GRID_TAU:\n",
        "                        recs = recommend_with_params(alpha=a, w_tfidf=w, gamma=g,\n",
        "                                                     lambda_xq=lam, tau=tau,\n",
        "                                                     pool_m=POOL_M, exploration_tail=EXPLORATION_TAIL)\n",
        "                        if not recs:\n",
        "                            continue\n",
        "                        prec = precision_at_k(recs, relevant_indices, TOP_K)\n",
        "                        rec = recall_at_k(recs, relevant_indices, TOP_K)\n",
        "                        ndcg = ndcg_at_k(recs, relevant_indices, TOP_K)\n",
        "                        ild = intra_list_diversity(recs, X_tfidf)\n",
        "                        nov = novelty_bits(recs, votes)\n",
        "                        cov = coverage_rate(recs, len(df))\n",
        "                        # dissimilarity for serendipity (use previously computed dissimilarity)\n",
        "                        ser = serendipity(recs, relevant_indices, dissimilarity)\n",
        "                        # objective: recall + 0.25*coverage + 0.25*serendipity\n",
        "                        obj = rec + 0.25 * cov + 0.25 * ser\n",
        "                        if obj > best_obj:\n",
        "                            best_obj = obj\n",
        "                            best_params = {\"alpha\": a, \"w_tfidf\": w, \"gamma\": g, \"lambda_xq\": lam, \"tau\": tau}\n",
        "                            best_list = recs\n",
        "    print(\"Auto-tune finished. Best params:\", best_params)\n",
        "else:\n",
        "    best_list = recommend_with_params(alpha=best_params[\"alpha\"], w_tfidf=best_params[\"w_tfidf\"],\n",
        "                                      gamma=best_params[\"gamma\"], lambda_xq=best_params[\"lambda_xq\"],\n",
        "                                      tau=best_params[\"tau\"], pool_m=POOL_M, exploration_tail=EXPLORATION_TAIL)\n",
        "\n",
        "# ----------------------------\n",
        "# Final evaluation using best params\n",
        "# ----------------------------\n",
        "final_recs = best_list\n",
        "if not final_recs:\n",
        "    # fallback: run once with defaults\n",
        "    final_recs = recommend_with_params(alpha=best_params[\"alpha\"], w_tfidf=best_params[\"w_tfidf\"],\n",
        "                                       gamma=best_params[\"gamma\"], lambda_xq=best_params[\"lambda_xq\"],\n",
        "                                       tau=best_params[\"tau\"], pool_m=POOL_M, exploration_tail=EXPLORATION_TAIL)\n",
        "\n",
        "prec = precision_at_k(final_recs, relevant_indices, TOP_K)\n",
        "recall = recall_at_k(final_recs, relevant_indices, TOP_K)\n",
        "ndcg = ndcg_at_k(final_recs, relevant_indices, TOP_K)\n",
        "ild = intra_list_diversity(final_recs, X_tfidf)\n",
        "nov = novelty_bits(final_recs, votes)\n",
        "cov = coverage_rate(final_recs, len(df))\n",
        "ser = serendipity(final_recs, relevant_indices, dissimilarity)\n",
        "sent_mean = float(np.mean(sent_scores[final_recs])) if final_recs else 0.0\n",
        "sent_var = float(np.var(sent_scores[final_recs])) if final_recs else 0.0\n",
        "\n",
        "print(\"\\n=== Recommendation Metrics (Final) ===\")\n",
        "print(f\"Precision@{TOP_K}: {prec:.4f}\")\n",
        "print(f\"Recall@{TOP_K}: {recall:.4f}\")\n",
        "print(f\"NDCG@{TOP_K}: {ndcg:.4f}\")\n",
        "print(f\"Intra-list Diversity (ILD): {ild:.4f}\")\n",
        "print(f\"Novelty (avg −log2 p): {nov:.4f}\")\n",
        "print(f\"Coverage: {cov:.4f}\")\n",
        "print(f\"Serendipity: {ser:.4f}\")\n",
        "print(f\"Sentiment mean: {sent_mean:.4f}, variance: {sent_var:.6f}\")\n",
        "print(\"Best params ->\", best_params)\n",
        "\n",
        "# ----------------------------\n",
        "# Save outputs (final CSV + metrics)\n",
        "# ----------------------------\n",
        "final_df = df.loc[final_recs].copy()\n",
        "final_df = final_df.reset_index(drop=False).rename(columns={\"index\": \"item_index\"})\n",
        "\n",
        "# recompute base scores using best params to store\n",
        "alpha_b = best_params[\"alpha\"]\n",
        "w_tfidf_b = best_params[\"w_tfidf\"]\n",
        "gamma_b = best_params.get(\"gamma\", 0.0)\n",
        "uaum_b, base_b, pred_proxy_b, quality_b, unexp_b, pop_pen_b = compute_uaum_and_base(alpha_b, w_tfidf_b, gamma_b)\n",
        "\n",
        "final_df[\"FinalScore\"] = base_b[final_recs]\n",
        "final_df[\"UAUM\"] = uaum_b[final_recs]\n",
        "final_df[\"PredRatingProxy\"] = pred_proxy_b[final_recs]\n",
        "final_df[\"Quality\"] = quality_b[final_recs]\n",
        "final_df[\"Unexpectedness\"] = unexp_b[final_recs]\n",
        "final_df[\"SentimentScore\"] = sent_scores[final_recs]\n",
        "final_df[\"PopularityNorm\"] = pop_norm[final_recs]\n",
        "final_df[\"Aspect\"] = aspect[final_recs]\n",
        "\n",
        "final_df.to_csv(FINAL_PATH, index=False)\n",
        "\n",
        "metrics = {\n",
        "    \"Precision@K\": prec,\n",
        "    \"Recall@K\": recall,\n",
        "    \"NDCG@K\": ndcg,\n",
        "    \"ILD\": ild,\n",
        "    \"Novelty\": nov,\n",
        "    \"Coverage\": cov,\n",
        "    \"Serendipity\": ser,\n",
        "    \"SentimentMean\": sent_mean,\n",
        "    \"SentimentVar\": sent_var,\n",
        "    \"Best_ALPHA\": alpha_b,\n",
        "    \"Best_W_TFIDF\": w_tfidf_b,\n",
        "    \"Best_GAMMA\": gamma_b,\n",
        "    \"Best_LAMBDA_XQ\": best_params.get(\"lambda_xq\"),\n",
        "    \"Best_TAU\": best_params.get(\"tau\"),\n",
        "}\n",
        "pd.DataFrame([metrics]).to_csv(METRICS_PATH, index=False)\n",
        "\n",
        "print(f\"\\nSaved recommendations -> {FINAL_PATH}\")\n",
        "print(f\"Saved metrics summary -> {METRICS_PATH}\")\n"
      ]
    }
  ]
}